title: "Demo fasttext-bloom vectors for UD Finnish TDT"
description: "Train fasttext-bloom vectors on OSCAR and compare standard vectors vs. fasttext-bloom vectors on UD Finnish TDT."
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "ftb_fi_ud_demo"
  lang: "fi"
  oscar_dataset: "unshuffled_deduplicated_fi"
  max_texts: 10000000
  vector_size: 50000
  vector_dim: 300
  n_process: 8
  minn: 4
  maxn: 5
  max_steps: 20000
  treebank: "UD_Finnish-TDT"
  train_name: "fi_tdt-ud-train"
  dev_name: "fi_tdt-ud-dev"
  test_name: "fi_tdt-ud-test"
  corpus_ner: "turku-ner-corpus"
  gpu_id: -1

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "corpus", "training", "metrics", "software", "training", "vectors"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded.
assets:
  - dest: "software/fasttext-bloom"
    git:
      repo: "https://github.com/adrianeboyd/fastText/"
      branch: "feature/bloom"
      path: ""
  - dest: "assets/${vars.treebank}"
    git:
      repo: "https://github.com/UniversalDependencies/${vars.treebank}"
      branch: "master"
      path: ""
  - dest: "assets/${vars.corpus_ner}"
    git:
      repo: "https://github.com/TurkuNLP/turku-ner-corpus"
      branch: "master"
      path: ""

## Workflows are sequences of commands (see below) executed in order. You can
## run them via "spacy project run [workflow]". If a commands's inputs/outputs
## haven't changed, it won't be re-run.
workflows:
  all:
    - compile-fasttext
    - tokenize-oscar
    - train-fasttext-standard
    - train-fasttext-bloom
    - init-standard-unpruned-vectors
    - init-standard-vectors
    - init-bloom-vectors
    - convert
    - train-no-vectors
    - train-standard-unpruned
    - train-standard
    - train-bloom
    - evaluate
    - convert-ner
    - train-no-vectors-ner
    - train-standard-unpruned-ner
    - train-standard-ner
    - train-bloom-ner
    - evaluate-ner

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "compile-fasttext"
    help: "Compile fasttext-bloom"
    script:
      - "make -j ${vars.n_process} -C software/fasttext-bloom"
    # this doesn't really work, the no_skip bug fix is needed
    outputs:
      - "software/fasttext-bloom/fasttext-bloom"
    no_skip: true

  - name: "tokenize-oscar"
    help: "Download, tokenize, and sentencize data"
    script:
      - "python scripts/tokenize_dataset.py ${vars.lang} ${vars.oscar_dataset} ${vars.max_texts} corpus/${vars.oscar_dataset}.${vars.max_texts}.tok.txt --n-process=${vars.n_process}"
    deps:
      - "scripts/tokenize_dataset.py"
    outputs:
      - "corpus/${vars.oscar_dataset}.${vars.max_texts}.tok.txt"

  - name: "train-fasttext-standard"
    help: "Train standard fasttext vectors"
    script:
      - "software/fasttext-bloom/fasttext-bloom cbow -dim ${vars.vector_dim} -minCount 50 -minn ${vars.minn} -maxn ${vars.maxn} -neg 10 -thread ${vars.n_process} -input corpus/${vars.oscar_dataset}.${vars.max_texts}.tok.txt -output vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10"
    deps:
      - "corpus/${vars.oscar_dataset}.${vars.max_texts}.tok.txt"
    outputs:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.vec"

  - name: "train-fasttext-bloom"
    help: "Train fasttext-bloom vectors"
    script:
      - "software/fasttext-bloom/fasttext-bloom cbow -dim ${vars.vector_dim} -minCount 50 -minn ${vars.minn} -maxn ${vars.maxn} -neg 10 -hashOnly -hashCount 2 -bucket ${vars.vector_size} -thread ${vars.n_process} -input corpus/${vars.oscar_dataset}.${vars.max_texts}.tok.txt -output vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.hashOnly.hashCount2.bucket${vars.vector_size}"
    deps:
      - "corpus/${vars.oscar_dataset}.${vars.max_texts}.tok.txt"
    outputs:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.hashOnly.hashCount2.bucket${vars.vector_size}.hashvec"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.hashOnly.hashCount2.bucket${vars.vector_size}.vec"

  - name: "init-standard-unpruned-vectors"
    help: "Create a standard unpruned vectors model"
    script:
      - "python -m spacy init vectors xx vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.vec vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_unpruned_model"
    deps:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.vec"
    outputs:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_unpruned_model"

  - name: "init-standard-vectors"
    help: "Create a standard vectors model"
    script:
      - "python -m spacy init vectors xx vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.vec vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_model --prune ${vars.vector_size}"
    deps:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.vec"
    outputs:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_model"

  - name: "init-bloom-vectors"
    help: "Create an ngram vectors model"
    script:
      - "python -m spacy init vectors xx vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.hashOnly.hashCount2.bucket${vars.vector_size}.hashvec vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_ngram_model --fasttext-bloom-vectors"
    deps:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.dim${vars.vector_dim}.minCount50.n${vars.minn}-${vars.maxn}.neg10.hashOnly.hashCount2.bucket${vars.vector_size}.hashvec"
    outputs:
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_ngram_model"

  - name: "convert"
    help: "Convert the data to spaCy's format"
    script:
      - "mkdir -p corpus/${vars.treebank}"
      - "python -m spacy convert assets/${vars.treebank}/${vars.train_name}.conllu corpus/${vars.treebank}/ --n-sents 10"
      - "mv corpus/${vars.treebank}/${vars.train_name}.spacy corpus/${vars.treebank}/train.spacy"
      - "python -m spacy convert assets/${vars.treebank}/${vars.dev_name}.conllu corpus/${vars.treebank}/ --n-sents 10"
      - "mv corpus/${vars.treebank}/${vars.dev_name}.spacy corpus/${vars.treebank}/dev.spacy"
      - "python -m spacy convert assets/${vars.treebank}/${vars.test_name}.conllu corpus/${vars.treebank}/ --n-sents 10"
      - "mv corpus/${vars.treebank}/${vars.test_name}.spacy corpus/${vars.treebank}/test.spacy"
    deps:
      - "assets/${vars.treebank}/"
    outputs:
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
      - "corpus/${vars.treebank}/test.spacy"

  - name: "train-no-vectors"
    help: "Train the model without vectors"
    script:
      - "python -m spacy train configs/config.cfg --output training/${vars.treebank}-novectors/ --paths.train corpus/${vars.treebank}/train.spacy --paths.dev corpus/${vars.treebank}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors null --components.tok2vec.model.embed.include_static_vectors false --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config.cfg"
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
    outputs:
      - "training/${vars.treebank}-novectors/model-best"

  - name: "train-standard-unpruned"
    help: "Train the model with standard, unpruned vectors"
    script:
      - "python -m spacy train configs/config.cfg --output training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/ --paths.train corpus/${vars.treebank}/train.spacy --paths.dev corpus/${vars.treebank}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_unpruned_model --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config.cfg"
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_unpruned_model"
    outputs:
      - "training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/model-best"

  - name: "train-standard"
    help: "Train the model with standard, pruned vectors"
    script:
      - "python -m spacy train configs/config.cfg --output training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/ --paths.train corpus/${vars.treebank}/train.spacy --paths.dev corpus/${vars.treebank}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_model --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config.cfg"
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_model"
    outputs:
      - "training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/model-best"

  - name: "train-bloom"
    help: "Train the model with ngram vectors"
    script:
      - "python -m spacy train configs/config.cfg --output training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/ --paths.train corpus/${vars.treebank}/train.spacy --paths.dev corpus/${vars.treebank}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_ngram_model --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config.cfg"
      - "corpus/${vars.treebank}/train.spacy"
      - "corpus/${vars.treebank}/dev.spacy"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_ngram_model"
    outputs:
      - "training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/model-best"

  - name: "evaluate"
    help: "Evaluate the models and export metrics"
    script:
      - "mkdir -p metrics/${vars.treebank}-novectors"
      - "python -m spacy evaluate training/${vars.treebank}-novectors/model-best corpus/${vars.treebank}/test.spacy --output metrics/${vars.treebank}-novectors/metrics.json --gpu-id ${vars.gpu_id}"
      - "mkdir -p metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned"
      - "python -m spacy evaluate training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/model-best corpus/${vars.treebank}/test.spacy --output metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/metrics.json --gpu-id ${vars.gpu_id}"
      - "mkdir -p metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard"
      - "python -m spacy evaluate training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/model-best corpus/${vars.treebank}/test.spacy --output metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/metrics.json --gpu-id ${vars.gpu_id}"
      - "mkdir -p metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom"
      - "python -m spacy evaluate training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/model-best corpus/${vars.treebank}/test.spacy --output metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/metrics.json --gpu-id ${vars.gpu_id}"
    deps:
      - "corpus/${vars.treebank}/test.spacy"
      - "training/${vars.treebank}-novectors/model-best"
      - "training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/model-best"
      - "training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/model-best"
      - "training/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/model-best"
    outputs:
      - "metrics/${vars.treebank}-novectors/metrics.json"
      - "metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/metrics.json"
      - "metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/metrics.json"
      - "metrics/${vars.treebank}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/metrics.json"

  - name: "convert-ner"
    help: "Convert the data to spaCy's format"
    script:
      - "mkdir -p corpus/${vars.corpus_ner}"
      - "python -m spacy convert assets/${vars.corpus_ner}/data/conll/train.tsv corpus/${vars.corpus_ner}/ -c ner --n-sents 10"
      - "python -m spacy convert assets/${vars.corpus_ner}/data/conll/dev.tsv corpus/${vars.corpus_ner}/ -c ner --n-sents 10"
      - "python -m spacy convert assets/${vars.corpus_ner}/data/conll/test.tsv corpus/${vars.corpus_ner}/ -c ner --n-sents 10"
    deps:
      - "assets/${vars.corpus_ner}/"
    outputs:
      - "corpus/${vars.corpus_ner}/train.spacy"
      - "corpus/${vars.corpus_ner}/dev.spacy"
      - "corpus/${vars.corpus_ner}/test.spacy"

  - name: "train-no-vectors-ner"
    help: "Train the model without vectors"
    script:
      - "python -m spacy train configs/config_ner.cfg --output training/${vars.corpus_ner}-novectors/ --paths.train corpus/${vars.corpus_ner}/train.spacy --paths.dev corpus/${vars.corpus_ner}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors null --components.tok2vec.model.embed.include_static_vectors false --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config_ner.cfg"
      - "corpus/${vars.corpus_ner}/train.spacy"
      - "corpus/${vars.corpus_ner}/dev.spacy"
    outputs:
      - "training/${vars.corpus_ner}-novectors/model-best"

  - name: "train-standard-unpruned-ner"
    help: "Train the model with standard, unpruned vectors"
    script:
      - "python -m spacy train configs/config_ner.cfg --output training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/ --paths.train corpus/${vars.corpus_ner}/train.spacy --paths.dev corpus/${vars.corpus_ner}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_unpruned_model --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config_ner.cfg"
      - "corpus/${vars.corpus_ner}/train.spacy"
      - "corpus/${vars.corpus_ner}/dev.spacy"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_unpruned_model"
    outputs:
      - "training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/model-best"

  - name: "train-standard-ner"
    help: "Train the model with standard, pruned vectors"
    script:
      - "python -m spacy train configs/config_ner.cfg --output training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/ --paths.train corpus/${vars.corpus_ner}/train.spacy --paths.dev corpus/${vars.corpus_ner}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_model --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config_ner.cfg"
      - "corpus/${vars.corpus_ner}/train.spacy"
      - "corpus/${vars.corpus_ner}/dev.spacy"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_standard_model"
    outputs:
      - "training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/model-best"

  - name: "train-bloom-ner"
    help: "Train the model with ngram vectors"
    script:
      - "python -m spacy train configs/config_ner.cfg --output training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/ --paths.train corpus/${vars.corpus_ner}/train.spacy --paths.dev corpus/${vars.corpus_ner}/dev.spacy --gpu-id ${vars.gpu_id} --initialize.vectors vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_ngram_model --training.max_steps ${vars.max_steps}"
    deps:
      - "configs/config_ner.cfg"
      - "corpus/${vars.corpus_ner}/train.spacy"
      - "corpus/${vars.corpus_ner}/dev.spacy"
      - "vectors/${vars.oscar_dataset}.${vars.max_texts}.n${vars.minn}-${vars.maxn}_ngram_model"
    outputs:
      - "training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/model-best"

  - name: "evaluate-ner"
    help: "Evaluate the models and export metrics"
    script:
      - "mkdir -p metrics/${vars.corpus_ner}-novectors"
      - "python -m spacy evaluate training/${vars.corpus_ner}-novectors/model-best corpus/${vars.corpus_ner}/test.spacy --output metrics/${vars.corpus_ner}-novectors/metrics.json --gpu-id ${vars.gpu_id}"
      - "mkdir -p metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned"
      - "python -m spacy evaluate training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/model-best corpus/${vars.corpus_ner}/test.spacy --output metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/metrics.json --gpu-id ${vars.gpu_id}"
      - "mkdir -p metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard"
      - "python -m spacy evaluate training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/model-best corpus/${vars.corpus_ner}/test.spacy --output metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/metrics.json --gpu-id ${vars.gpu_id}"
      - "mkdir -p metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom"
      - "python -m spacy evaluate training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/model-best corpus/${vars.corpus_ner}/test.spacy --output metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/metrics.json --gpu-id ${vars.gpu_id}"
    deps:
      - "corpus/${vars.corpus_ner}/test.spacy"
      - "training/${vars.corpus_ner}-novectors/model-best"
      - "training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/model-best"
      - "training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/model-best"
      - "training/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/model-best"
    outputs:
      - "metrics/${vars.corpus_ner}-novectors/metrics.json"
      - "metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard-unpruned/metrics.json"
      - "metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-standard/metrics.json"
      - "metrics/${vars.corpus_ner}.${vars.max_texts}.n${vars.minn}-${vars.maxn}-bloom/metrics.json"
